---
title: "Pset4"
author: "Yu Hui, Janet Cao"
output: pdf_document
date: "2024-04-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = 'hold')
#setwd(dirname(rstudioapi::getSourceEditorContext()$path))
library(dplyr)
library(tibble)
library(stats)
library(systemfit)
library(sandwich)
```

\textcolor{red}{\textbf{Objective}: In Pset3 you estimated the ATE of the offer of training on post-training earnings using NSW experimental data. The Treatment-Control difference in sample averages indicates that the offer of training causes an additional \$1,794 in terms of 1978 earnings. Variation in the cause/treatment is often observational in nature, instead of resulting from an RCT. In this Pset you utilize methods developed to estimate the effect of the offer of training using \textcolor{green}{``observational data''} and apply them to two datasets that Dehajia and Wahba constructed to \underline{mimic} observational data.}\

\textcolor{red}{\textbf{Background}: Consider the files \texttt{nswcps.csv} and \texttt{nswpsid.csv}. Each file contains a dataset. Each dataset combines two samples: 1) the treated sample from the Dehajia and Wahba's NSW data (i.e., 185 males offered NSW training in 1976-1977)\footnote{Dehejia and Wahba (1999) Causal Effects in Nonexperimental Studies: reevaluating the Evaluation of Training Programs, \textit{JASA}, pp. 1053-1062. Dehejia and Wahba (2002) Propensity-score Matching Methods for Nonexperimental Causal Studies, \textit{ReStat}, pp. 151-161.}; and 2) a sample extracted from a large survey: a) in \texttt{nswcps.csv}, such sample is the Current Population Survey (\href{https://www.census.gov/cps/data/}{CPS}); b) in \texttt{nswpsid.csv}, such sample is the Panel Study of Income Dynamics (\href{https://psidonline.isr.umich.edu/}{PSID}). The samples in 2) contain data on a \textcolor{green}{comparison group}, that is, on subjects who (as far as we know) did not receive the NSW offer of training.\footnote{When working with observational data the \textcolor{green}{untreated} sample is more properly called a \textcolor{green}{comparison group}. Nevertheless it is common to use the terms \textcolor{green}{control} and \textcolor{green}{comparison} interchangeably, irrespective of whether the variation in the treatment indicator is induced by RA or not.} Specifically, the PSID sample (called \textbf{PSID-1}) consists of 2,490 male household heads under the age of 55 who are not retired; and, the CPS sample (called \textbf{CPS-1}) consists of 15,992 male household heads under the age of 55 who are not retired. The file \texttt{nswcps.csv} (respectively, \texttt{nswpsid.csv}) contains the treated individuals (from NSW-treated) along with the PSID (respectively, CPS) comparison individuals. The treatment indicator variable \texttt{treat} equals 1 for individuals in the NSW-treated sample and zero for the PSID (respectively, CPS) comparison individuals.}  

## Part 1: Describe the Data (10 p)
### Q1(4 p) Fill Table 1 columns 5 and 6 using, respectively, the data in \texttt{nswpsid.csv} and in \texttt{nswcps.csv}. \textcolor{black}{\textbf{Notes}: You want to limit attention to observations with \texttt{treat=0}. You filled columns 3 and 4 in PSet 3.}

```{r}
#import data
df.psid<-read.csv("nswpsid.csv")
df.cps <-read.csv("nswcps.csv")

# summarizePSID
table.psid<-df.psid[df.psid$treat==0,]%>%
summarize_all(list(~mean(.)))%>%#summarizemean
mutate_all(list(~round(.,3)))%>% #limitdigits
t()%>% #transpose
as.data.frame()
colnames(table.psid)<-c("psid_control")
table.psid<-tibble::rownames_to_column(table.psid,"varname")

#summarizeCPS
table.cps<-df.cps[df.cps$treat==0,]%>%
summarize_all(list(~mean(.)))%>%#summarizemean
mutate_all(list(~round(.,3)))%>% #limitdigits
t()%>% #transpose
as.data.frame()
colnames(table.cps)<-c("cps_control")
table.cps<-tibble::rownames_to_column(table.cps,"varname")
table<-merge(table.psid,table.cps,by="varname")
knitr::kable(table)
```
### Q2 (4 p) Briefly comment on the completed Table 1.  \textcolor{black}{\textbf{Hint}: Are the PSID-1 and CPS-1 samples ``good'' control groups?}

We have tested in PSet 3 that the experiment control group is significantly different from the treatment group in nodegree. But the PSID-1 and CPS-1 sample has a even larger difference in characteristics compared to the treatment group. The PSID and CPS sample are 8 to 9 years older, about 70% more likely to be married, 50% more likely to finish 12-year education,and have 2 more years of education. The NSW sample is 50% more likely to be black. The survey sample’s earnings in 1974, 1975, and 1978 are more than 10,000 dolars higher than the NSW sample.
For the pre-determined variables, we can conclude that the the sample extracted from a large survey is different from the individuals placed in NSW training program. In general, the worker group selected to participate in RCT is under disadvantage in labor market compared to the whole population. Therefore, using survey sample as control of the treated group in NSW is not appropriate and will lead as to very biased (probably downwards) estimates of ATE.

### Q3 (2 p) Why do you think that Dehajia and Wahba constructed their ``observational datasets'' by pulling together the treated sample from NSW and a sample of individuals drawn from either the PSID or the CPS data?

Although both PSID and CPS include information on whether an individual enrolled in a training course during the previous 12 months, this enrollment is not guaranteed to be random. Exclusively exploiting the observational variation in whether an individual enrolled in a training program will not lead to a causal interpretation. The treatment and control in this approach is unlikely to have the same potential outcome w/ or w/o treatment. The NSW experiment data ensures that the training assignment is random. Using these as the treatment group makes it more likely to identify ATE with some adjustment. For example, though the control group is drastically different to the treatment group in OPVs now, we can attempt propensity score matching approach to solve this concern.

## Part 2: Regression-based Estimation of TEs (90 p)
You use the \texttt{nswpsid.csv} dataset to estimate the treatment effect (TE) of the offer of training via \textcolor{green}{regression-based approaches} associated with the following three specifications of the outcome equation:
\begin{eqnarray}
re78_{i} &=&\alpha +\rho D_{i}+u_{i}\text{, }i=1,...,2675\text{,}
\label{TCcomp} \\
re78_{i} &=&\alpha +\rho D_{i}+\mathbf{x}_{i}^{\prime }\mathbf{\beta }+u_{i}\text{, }i=1,...,2675\text{,}  \label{CFnc} \\
re78_{i} &=&\rho D_{i}+g(\mathbf{x}_{i})+u_{i}\text{, }i=1,...,2675\text{,}  \label{PLR} 
\end{eqnarray}
\noindent Subscript $i$ denotes an individual.  Also: 1) $re78_{i}$ represents the data field \texttt{re78}; 2) $D_{i}$ represents the data field \texttt{treat}; 3) $\mathbf{x}_{i}$ represents a $K\times 1$ vector of observed pre-determined variables (OPVs); and, 4) $g(\cdot)$ is an unknown and possibly non-linear function (i.e., a generalization of $\alpha + \beta' \mathbf{x}_{i}$). Table \ref{tab:reg-specs}'s column [1] references the regression specification. Column [2] gives the name of the approach. Column [3] indicates the regression coefficient of interest. You complete columns [4] and [5] with the estimate of the regression coefficient and its standard error (SE).}

\begin{table}[ht!]
\centering
{\begin{tabular}{ccccc}
\hline
\textbf{Reference} & \multicolumn{1}{c}{\textbf{Name of the }} & \textbf{Parameter} & \multicolumn{1}{c}{\textbf{Estimate}} & \textbf{SE} \\
\textbf{Model} & \multicolumn{1}{c}{\textbf{Estimation Approach}}            & \textbf{of Interest} &  &  \\ \hline
[1] & [2] & [3] & [4] & [5]  \\ \hline
expression (\ref{TCcomp})                 & Treatment-Control Comparison (TCC)                  & $\rho$           &-15204.776   &1154.614   \\
expression (\ref{CFnc})                 & Regression-Adjusted Treatment-Control Comparison (Adj. TCC) & $\rho$          &217.9438   &655.6691  \\
expression (\ref{PLR})                 & Double Machine Learning (DML) & $\rho$           &-654.5  &1121.8  \\
\hline
\end{tabular}}
\caption{\textcolor{black}{Treatment Effect Estimates Based on Three Regression-Based Approaches Applied to Observational Data.}}
\label{tab:reg-specs}
\end{table}
## Treatment Control Comparison Approach
### Q4 (30 p) These questions pertain to the specification in expression (\ref{TCcomp}) thus you obtain the \textcolor{green}{Treatment-Control Comparison (TCC) Estimator} of the treatment effect of the offer of training.
### a) Estimate $\rho$. \textcolor{gray}{\textbf{Programming Guidance:} Use \texttt{stats::lm( )}. Say that your linear model is \texttt{m1 $<$- lm(re78 $\sim$ treat, data = df)}. View the SEs of estimator $\hat{\rho}$ by using \texttt{summary(m1)\$coefficients["treat", c("Estimate", "Std. Error"]}. View all SEs by using \texttt{lmtest::coeftest(m1, vcov. = vcov(m1))} which runs t-tests for each of the coefficients using the variance-covariance matrix estimated assuming \textcolor{green}{homoschedasticity}. Package \href{https://cran.r-project.org/web/packages/lmtest/lmtest.pdf}{\texttt{lmtest}} allows you to perform z and t tests on estimated coefficients from, among others, method \texttt{lm( )}. It returns a coefficient matrix with columns containing the estimates, associated SEs, test statistics, and p-values.}\label{item:TCcomp-rho} 
```{r}
df <- df.psid
m1 <- lm(re78 ~ treat, data = df) 
summary(m1)$coefficients["treat", c("Estimate", "Std. Error")]
coef1 <- summary(m1)$coefficients["treat", "Estimate"] 
coeftest(m1, vcov. = vcov(m1))
```
### b) (10 p) Compute \textcolor{green}{heteroschedasticity-robust} SEs.\textcolor{gray}{\textbf{Programming Guidance:} There are multiple R packages to estimate the variance-covariance matrix of $(\hat{\alpha},\hat{\rho})$ under general heteroschedasticity. Here are two ways. Option 1: Use \href{https://www.rdocumentation.org/packages/sandwich/versions/2.5-1/topics/vcovHC}{\texttt{sandwich::vcovHC(m1, type = ''HC0")}} from package \href{https://cran.r-project.org/web/packages/sandwich/sandwich.pdf}{\texttt{sandwich}}. Option 2: Use \href{https://www.rdocumentation.org/packages/car/versions/3.0-6/topics/hccm}{\texttt{car::hccm(m1, type = ''hc0")}} from package \href{https://cran.r-project.org/web/packages/car/car.pdf}{\texttt{car}}. In both cases, the argument \texttt{type = "hc0"} (or \texttt{"HC0"}) tells R that you want to use the variance covariance matrix estimated using White's (1980) estimator, often referred to as HCE (heteroscedasticity-consistent estimator).
```{r}
# the variance covariance matrix estimated using White’s (1980) estimator
vcovHC(m1, type = "HC0")
coeftest(m1, vcov.= vcovHC(m1, type = "HC0"))
```
### c) (2 p) Verify that $\hat{\rho}$ in \textbf{\ref{item:TCcomp-rho}} equals $(\overline{re78}^{D=1}-\overline{re78}^{D=0})$, i.e., the difference between the average post-training earnings of the treated and of the control individuals. This fact explains the name of the estimator, and is consistent with what you derived in previous Psets.\label{item:TCcomp-diff}
```{r}
mean.diff <- mean(df[df$treat==1, "re78"]) - mean(df[df$treat==0, "re78"]) 
mean.diff
coef1
```
### d) (10 p) Intuitively explain why the TCC approach may not deliver a credible estimate of the average effect of the treatment of interest. \textcolor{gray}{\textbf{Hint}: Use the result in  \textbf{\ref{item:TCcomp-diff}} to think about what this approach uses to proxy for the missing data, i.e., for the control units' mean of the potential outcome w/ treatment, and for the treated units' mean of the potential outcome w/out treatment.}
In the Treatment-Control Comparison (TCC) approach, the mean difference in outcome between the control and treatment group is taken as the average treatment effect (ATE). The ATE is defined as:
\begin{equation}
\begin{aligned}
\text{ATE} &\equiv \mathbb{E}[y_{1i} - y_{0i} \mid D_i = 1] \Pr(D_i = 1) + \mathbb{E}[y_{1i} - y_{0i} \mid D_i = 0] \Pr(D_i = 0) \\
&= [\mathbb{E}[y_{1i} \mid D_i = 1] - \mathbb{E}[y_{0i} \mid D_i = 1]] \Pr(D_i = 1) \\
&\quad + [\mathbb{E}[y_{1i} \mid D_i = 0] - \mathbb{E}[y_{0i} \mid D_i = 0]] \Pr(D_i = 0) \\
&= [\mathbb{E}[y_{i} \mid D_i = 1] - \mathbb{E}[y_{0i} \mid D_i = 1]] \Pr(D_i = 1) \\
&\quad + [\mathbb{E}[y_{1i} \mid D_i = 0] - \mathbb{E}[y_{i} \mid D_i = 0]] \Pr(D_i = 0).
\end{aligned}
\end{equation}
This approach uses the control units' mean outcome without treatment to proxy the treated units' mean potential outcome without treatment, and uses treated units' mean outcome with treatment to proxy control units' mean potential outcome with treatment.

The reliability of the above actions strongly relies on the assumption that the treated react the same as the controlled when facing treatment. Usually, researchers provide evidence on this assumption by testing balance on pre-determined variables. Providing that two groups are not significantly different in observed pre-determined characteristics, researchers may argue that we can compare the two groups for ATE.

However, as we have discussed in Part 1, the treated group from the NSW experimental data and the control group from the PSID survey sample, are highly unbalanced. That is, the MIA assumption may fail in this context, indicating that $\mathbb{E}[y_{1i} \mid D_i = 1] \neq \mathbb{E}[y_{1i} \mid D_i = 0]$ and $\mathbb{E}[y_{0i} \mid D_i = 1] \neq \mathbb{E}[y_{0i} \mid D_i = 0]$. They are drastically different in almost all aspects like average age, education level, marriage status, and pre-treatment earnings. This explains why we obtain a highly unreliable ATE estimate of \$$-15204.78$ for the training.

## Control Fnc Approach
### Q5: (20 p) These questions pertain to the specification in expression (\ref{CFnc}) thus you obtain the \textcolor{green}{Regression-Adjusted Treatment-Control Comparison (Adj. TCC) Estimator} of the treatment effect of the offer of training. \label{item:CFnc}
### a) (10 p) Add to the model estimated in \textbf{\ref{item:TCcomp}} the following OPVs as regression covariates: \texttt{age}, \texttt{agesq}, \texttt{edu}, \texttt{nodegree}, \texttt{black}, \texttt{hisp}, \texttt{re74}, and \texttt{re75}. Report $\hat{\rho}$ and its heteroschedasticity-robust SE. \textcolor{gray}{\textbf{Programming Guidance:} Add column \texttt{agesq} (\texttt{age} squared) to your dataframe using, e.g., \texttt{dplyr::mutate( )}.}\label{item:CFnc-rho}

```{r}
df <- mutate(df, agesq=age*age)
m2 <- lm(re78 ~ treat + age + agesq + edu + nodegree + black + hisp + re74 + re75, data = df) 
rho2 <- summary(m2)$coefficients["treat","Estimate"]
rho2

```
```{r}
se2 <- coeftest(m2, vcov.= vcovHC(m2, type = "HC0"))["treat", "Std. Error"]
se2
```


### b) (10 p) Intuitively explain why the Adj. TCC approach may be regarded as an improvement over the TCC approach when it comes to credible identification/estimation of average treatment effects.

As mentioned above, the problem with the Treatment-Control Comparison (TCC) approach lies in the fact that the control group is nowhere near balanced compared to the treatment group. It is intuitive that these observed pre-determined variables (OPVs) can be strongly related to income. Without controlling for these variables, the estimates mix treatment effects with the earning effects contributed by differences in OPVs for the two groups.

By adding the OPVs like \textit{age}, \textit{agesq}, \textit{edu}, \textit{nodegree}, \textit{black}, \textit{hisp}, \textit{re74}, and \textit{re75}, we can partial out the effects of the observed variables on the outcome earnings. To be more specific, the estimates are closer to the Average Treatment Effect (ATE) because we are comparing the difference between the treatment and control group on the residual of outcome earnings after regressing on all the OPVs. This is an improvement (as we can see the coefficient estimate is now 217.9438, at least positive) since we observe sharp differences in OPVs between the PSID survey sample and the NSW sample.

In mathematical language, we are assuming a weaker assumption, the Conditional Mean Independence Assumption (CMIA): 
\begin{equation}
\mathbb{E}[y_{ji} \mid D_i, x_i] = \mathbb{E}[y_{ji} \mid x_i] \quad \forall j = 0, 1; \quad \forall x_i.
\end{equation}
For each $x$ cell, we estimate the Conditional Average Treatment Effect (CATE).

For OPVs that do not predict treatment, adding them can account for some variation in $re78_i$, hence increasing the precision of the estimator of $\hat{\rho}$. The Standard Error (SE) of ATE will decrease and we can better discriminate among competing hypotheses concerning the Treatment Effect (TE).


## Partialing Out
### Q6 (20 p)  Consider again the specification in expression 2 estimated in Q2. Here, you implement two procedures, as detailed below, to verify the “partialling-out” interpretation of OLS coefficients in MLRM. 
### (a) (8 p) Procedure A: (i) (4 p) First Stage:  Regress treat on a constant and the OPVs listed. ii. (4p) Second Stage: Regress re78on a constant and the residuals from the previous question

```{r}
# First Stage
 s1 <- lm(treat ~ age + agesq + edu + nodegree + black + hisp + re74 + re75, data = df)
 df$r1 <- resid(s1) # residual
 # Second Stage
 s2 <- lm(re78 ~ r1, data = df)
 rho2a <- summary(s2)$coefficients["r1","Estimate"]
 rho2a
 

```

### (b) (8 p) Procedure B:
### (i) (4 p)(0 p) First Stage: Same as Q6ai
### (ii) (4 p)First Stage: Regress \texttt{re78} on a constant and the OPVs listed in Q5a; obtain the residuals.\label{item:CFnc-po-3rdstep}
### (iii) (4 p)(4 p) Second Stage: Regress the residuals from Q6bii on the residuals from Q6Bi.\label{item:CFnc-po-4thstep}

```{r}
# First Stage
s1a <- lm(treat ~ age + agesq + edu + nodegree + black + hisp + re74 + re75, data = df)
df$r1 <- resid(s1) # residual
s1b <- lm(re78 ~ age + agesq + edu + nodegree + black + hisp + re74 + re75, data = df)
df$r2 <- resid(s1b) # residual of s1b
# Second Stage
s2b <- lm(r2 ~ r1, data = df)
rho2b <- summary(s2b)$coefficients["r1","Estimate"]
rho2b
```
### (c)  (4p) Verify that the estimates of the slope coefficient from Q3(a)ii and Q3(b)iii are numerically identical to $\hat{\rho}$ obtained in Q2a. Use this fact to give meaning to the expression “partialling-out” interpretation of OLSin a MLRM.
```{r}
rho2
```

```{r}
rho2a
```


```{r}
rho2b
```

The three estimates are numerically identical. According to the background, OLS is essentially partialling-out the effects of a constant on both $D_i$ and $y_i$.

If we extend the constant to a series of OPVs, MLRM is equivalent to (1) partialling out the OPVs' effects on $D_i$ and then (2) regressing $y_i$ on the residuals from the previous step. This is why the Q2a (MLRM) estimate equals to the Q3a estimate.

Since in Q3a, we have partialed out OPVs' effects on $D_i$ before checking $D_i$'s effects on $y_i$, the estimate does not contain the effects of OPVs. So, if we also partial out the OPVs effects on $y_i$, the regression of residuals on residuals (Q3b) is identical to Q3a. We have shown that this conclusion holds.

## DoubleML

### Q4 (20 p) Consider the \textcolor{green}{partially-linear specification} in expression. Here you estimate $\rho$ via the the \textcolor{green}{Double Machine Learning (DML)} estimation procedure of Robinson (1988)\footnote{Robinson, P. M. (1988). Root-N-consistent semi-parametric regression. Econometrica 56, 931-54. 

### (a) (2 p)  Install four R packages: DoubleML, data.table, mlr3, and mlr3learners.
```{r}
# install.packages("DoubleML")
# install.packages("data.table")
# install.packages("mlr3")
# install.packages("mlr3learners")
# install.packages("ranger")
```
### (b) (2 p) If your data is not already a \texttt{data.table} object convert it. \textcolor{gray}{\textbf{Programming Guidance:} Assuming that your dataframe is called \texttt{df}, use \texttt{dt <- data.table::as.data.table(df)}. \texttt{data.table} is an extension of \texttt{data.frame} and allows for fast manipulation of very large data.}
```{r}
# install.packages("data.table")
library(data.table)
dt <- as.data.table(df)
```
### (c) (2 p) Collect all the original OPVs in a list named, for example, \texttt{pretreat\_colnames}. Note: Henceforth when we refer to these OPVs in mathematical expressions we use the notation $\mathbf{x}_{i}$.
```{r}
pretreat_colnames <- c("age", "edu", "nodegree", "black", "hisp", "married","u74", "u75", "re74", "re75")
```
### (d) (2 p) Specify data and variables for the causal model by running the script:\label{item:dml-data}

```{r}
dml_data_psid <- DoubleML::DoubleMLData$new(dt,
                            y_col = "re78",
                            d_cols = "treat",
                            x_cols = pretreat_colnames)
```

### (e) (2 p) Suppress messages from the \texttt{mlr3} package by adding \texttt{lgr::get\_logger("mlr3")\$set\_threshold("warn")} to your script.
```{r}
lgr::get_logger("mlr3")$set_threshold("warn")
```
### (f) (2 p) Here you mimic the first stage of Procedure B in Q3b. Namely, you specify the model for the two regression functions $l(\mathbf{x})=E[\texttt{re78}_i|\mathbf{x}_{i}=\mathbf{x}]$ and $m(\mathbf{x})=E[\texttt{treat}_i|\mathbf{x}_{i}=\mathbf{x}]$. In Q3b you used a linear-in-parameter model and a priori decided which OPVs to include and which transformations to apply to the OPVs to include (e.g., you excluded \texttt{u74}, you used both \texttt{age} and \texttt{agesq}, you left as-is the other included OPVs). Instead here you do not a priori exclude any OPVs, and you use flexible models, which accommodate complex non-linearities. Run the script:
```{r}
# Specify a RF model as the learner model for l(x)=E[re78|X=x]
ml_l_rf <- mlr3::lrn("regr.ranger")
# Specify a RF model as the learner model for m(x)=E[treat|X=x]
ml_m_rf <- mlr3::lrn("classif.ranger")
```
The above script uses a \textcolor{green}{Random Forest (RF) model} for both conditional expectations functions.\footnote{You do not need to know what a RFM is. Think of this approach as a way to flexibly estimate the form of a function of many variables. If you want to learn more about these approaches consider taking ECMA 31350 in Winter 2024.}

### (g) (2 p) Here you initialize \& parametrize the model object which you later use to perform estimation. Run the script:

```{r}
 # Set seeds for cross-fitting
 set.seed(3251)
 # Set the DML specification
 obj_dml_plr <- DoubleML::DoubleMLPLR$new(dml_data_psid, # from Q4d
                                        ml_l = ml_l_rf, ml_m = ml_m_rf,
                                        n_folds = 2,
                                        score = "partialling out",
                                        apply_cross_fitting = TRUE)
```


The above script: (i) utilizes the data object generated in Q4d, namely \texttt{dml\_data\_psid}; (ii) utilizes the models for the first stage regressions picked in Q4d, namely \texttt{ml\_l\_rf} and \texttt{ml\_m\_rf}; (iii) specifies that we want to split the sample into 2 parts (\texttt{n\_folds = 2}), and (iv) that we want to use the ``partialling out'' approach to estimate causal impacts (\texttt{score = "partialling out"}), and (v) that we want to apply \textcolor{green}{cross-fitting} (\texttt{apply\_cross\_fitting = TRUE}).\label{item:dml-model}

### (h) (2 p) Here you fit the DML model defined in \textbf{\ref{item:dml-model}}. Run the script:

```{r}
obj_dml_plr$fit()
obj_dml_plr
```
At a high level the above script implements all of the following operations: (i) fits the two models for the first stage selected in Q7f, (ii) gets residuals, (iii) regresses the residuals for the outcome variables onto the residuals for the treatment indicator to obtain the DML estimate of $\rho$ in expression (3). Note: You specified \texttt{n\_folds = 2} and requested \texttt{apply\_cross\_fitting = TRUE} in Q7g thus the 2-stage estimation procedure proceed as follows. First the entire data is split into two sub-samples, call them A and B (hence the term 2 folds). Sample A is used to fit the 1st stage models. These fitted models are used to compute residuals in sample B and these residuals are used to fit the 2nd stage model using only data in sample B. Denote the resulting estimate $\hat{\rho}_{AB}$. Then the samples are swapped (hence the term ``cross fitting'').\footnote{Cross-fitting is implemented to eliminate the bias from \textcolor{green}{overfitting} resulting from the fact that the two conditional mean functions $l(\cdot)$ and $m(\cdot)$ are estimated via ML models, in our case the RF models specified in \textbf{\ref{item:dml-first-stage-models}}.} That is, sample B is used to fit the 1st stage models. Sample A is used to fit the 2nd stage model. Denote the resulting estimate $\hat{\rho}_{BA}$. The DML estimate is the average of $\hat{\rho}_{AB}$ and $\hat{\rho}_{BA}$. 


The DML estimate of ATE is -560.5 (SE 1006.4).

### (i)(4 p) Take a look at the output, i.e., at the object \texttt{obj\_dml\_plr}. How does the DML estimate of average treatment effect compare to the estimates based on specifications (1) and (2)?


The Double Machine Learning (DML) model estimates the average treatment effect (ATE) at -560.5 with a standard error of 1006.4, a figure that falls between the significant negative estimate from the basic Specification 1 and the positive but smaller estimate from Specification 2. 

Neither the DML estimate nor that from Specification 2 are statistically significant at a 5\% level, indicating the data does not conclusively show a treatment effect different from zero. This may suggest an imbalance in OPVs between treated and untreated groups or other complexities in the data.

Specification 1, while statistically significant, is limited by its simplicity and may fail to address confounding factors. Conversely, Specification 2 accounts for OPVs but lacks the DML's sophistication in modeling non-linear effects, possibly leading to different results.



